version: '3.8'

# ====================================== AIRFLOW ENVIRONMENT VARIABLES =======================================
x-environment: &airflow_environment
  - AIRFLOW__API__AUTH_BACKEND=airflow.api.auth.backend.basic_auth
  - AIRFLOW__CORE__EXECUTOR=LocalExecutor
  - AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=False
  - AIRFLOW__CORE__LOAD_EXAMPLES=False
  - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://airflow:airflow@postgres:5432/airflow
  - AIRFLOW__CORE__STORE_DAG_CODE=True
  - AIRFLOW__CORE__STORE_SERIALIZED_DAGS=True
  - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
  - AIRFLOW_CONN_FS_DEFAULT=fs://@?path=/
  - AIRFLOW_CONN_MY_POSTGRES=postgresql://airflow:airflow@wiki_results:5432/airflow
  - _PIP_ADDITIONAL_REQUIREMENTS=clickhouse_driver
  - CLICKHOUSE_HOST=clickhouse
  - CLICKHOUSE_PORT=9000
  - CLICKHOUSE_USER=${CLICKHOUSE_USER}
  - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD}
  - CLICKHOUSE_DB=bronze

x-airflow-image: &airflow_image apache/airflow:2.4.2-python3.10
# ====================================== /AIRFLOW ENVIRONMENT VARIABLES ======================================

services:
  postgres:
    image: postgres:12-alpine
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"
    networks:
      airflow:

  init:
    image: *airflow_image
    depends_on:
      - postgres
    environment: *airflow_environment
    entrypoint: /bin/bash
    command: -c 'airflow db init && airflow users create --username admin --password admin --firstname Anonymous --lastname Admin --role Admin --email admin@example.org'
    networks:
      airflow:

  webserver:
    image: *airflow_image
    restart: always
    depends_on:
      - postgres
    ports:
      - "8080:8080"
    volumes:
      - logs:/opt/airflow/logs
    environment: *airflow_environment
    command: webserver
    networks:
      airflow:      
        
  scheduler:
    image: *airflow_image
    restart: always
    depends_on:
      - postgres
    volumes:
      - logs:/opt/airflow/logs
      - ./dags:/opt/airflow/dags
    environment: *airflow_environment
    command: scheduler
    networks:
      airflow:

  clickhouse:
    image: yandex/clickhouse-server
    hostname: clickhouse
    volumes:
      - clickhouse-data:/var/lib/clickhouse    
    environment:
      - CLICKHOUSE_USER=${CLICKHOUSE_USER}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD}
    ports:
      - "8123:8123"
      - "9000:9000"       
    networks:
      airflow:
        
  clickhouse-init:
    image: yandex/clickhouse-server
    volumes:
      - ./clickhouse:/var/clickhouse
      - ./initsql:/var/clickhouse/schema      
    depends_on:
      - clickhouse
    networks:
      - airflow
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      while ! clickhouse-client --host clickhouse --user ${CLICKHOUSE_USER} --password ${CLICKHOUSE_PASSWORD} -q \"SHOW databases;\"; do
          echo waiting for clickhouse up
          sleep 1
      done 

      clickhouse-client --host clickhouse --user ${CLICKHOUSE_USER} --password ${CLICKHOUSE_PASSWORD} --queries-file /var/clickhouse/schema/init_database.sql

      tail -f /dev/null       
      "        
               
volumes:
  logs:
  clickhouse-data:
  
networks:
  airflow:  
